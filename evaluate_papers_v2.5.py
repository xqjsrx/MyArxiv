import os
import json
import time
import re
from openai import OpenAI

# å¡«å†™APIçš„å¯†é’¥
API_KEY = os.getenv("API_KEY")

# ================= é…ç½®åŒºåŸŸ =================
# æ¨¡å‹åç§° (Batch API æ”¯æŒ qwen-plus, qwen-max ç­‰)
MODEL_NAME = "qwen-plus" 
# è½®è¯¢ç­‰å¾…æ—¶é—´ (ç§’)
POLL_INTERVAL = 60 
# æœ€å¤§ç­‰å¾…æ—¶é—´ (ç§’)ï¼Œé˜²æ­¢ Github Action è¶…æ—¶ (ä¾‹å¦‚è®¾ç½® 3å°æ—¶)
MAX_WAIT_TIME = 5 * 60 * 60 

# ================= æç¤ºè¯æ¨¡æ¿ (ä¿æŒä¸å˜) =================
# è‡ªå®šä¹‰çš„æç¤ºæ¨¡æ¿
PROMPT_TEMPLATE = """
æˆ‘æ˜¯ä¸€åäººå·¥æ™ºèƒ½æ–¹å‘çš„ç ”ç©¶ç”Ÿï¼Œæ ¸å¿ƒç ”ç©¶é¢†åŸŸæ˜¯ **æ–‡æ¡£å›¾åƒç†è§£ï¼ˆDIU / DocVQAï¼‰**ã€‚
æˆ‘çš„ç›®æ ‡æ˜¯åˆ©ç”¨ **VLM (Multimodal LLM)** æŠ€æœ¯è§£å†³æ–‡æ¡£ç†è§£ä¸­çš„æ ¸å¿ƒç—›ç‚¹ï¼ˆå¦‚OCRå¹»è§‰ã€å¯†é›†æ–‡æœ¬ã€å¤æ‚æ’ç‰ˆã€é•¿æ–‡æ¡£æ¨ç†ï¼‰ã€‚

è¯·æ‹…ä»»ä¸€å**æŒ‘å‰”çš„å®¡ç¨¿äºº**ï¼Œå¸®æˆ‘ç­›é€‰è®ºæ–‡ã€‚
**åŸåˆ™ï¼šä¸æ‹˜æ³¥äºç‰¹å®šæŠ€æœ¯è·¯çº¿ï¼ˆå¦‚å¿…é¡»æ˜¯Agentæˆ–å¿…é¡»æ˜¯Interventionï¼‰ï¼Œåªè¦èƒ½æå‡DIUæ€§èƒ½çš„åº•å±‚æ–¹æ³•éƒ½å€¼å¾—å…³æ³¨ï¼›ä½†åšå†³æŠµåˆ¶æ— è¥å…»çš„â€œå¹³è¡Œåº”ç”¨â€ã€‚**

### ğŸ›‘ è´Ÿé¢æ¸…å•ï¼ˆç›´æ¥æ‰“0-3åˆ†ï¼‰
**åªè¦å‘½ä¸­ä»¥ä¸‹ä»»æ„ä¸€ç‚¹ï¼Œæ— éœ€ç•™æƒ…ï¼Œç›´æ¥ä½åˆ†ï¼š**
1.  **å¹³è¡Œä¸‹æ¸¸åº”ç”¨ï¼ˆWrapper/Applicationï¼‰**ï¼š
    *   ä¾‹å¦‚ï¼šâ€œç”¨LLMè¿›è¡Œé‡‘èæŠ¥è¡¨åˆ†æâ€ã€â€œåŸºäºRAGçš„æ³•å¾‹æ–‡ä¹¦åŠ©æ‰‹â€ã€â€œåŒ»ç–—ç—…å†ç»“æ„åŒ–â€ã€‚
    *   **ç†ç”±**ï¼šè¿™äº›åªæ˜¯æŠŠç°æœ‰æŠ€æœ¯ç”¨åœ¨ç‰¹å®šæ•°æ®ä¸Šï¼Œæ²¡æœ‰æ–¹æ³•è®ºåˆ›æ–°ã€‚æˆ‘åªè¦æå‡ºæŠ€æœ¯æºå¤´çš„è®ºæ–‡ã€‚
2.  **æ— å…³é¢†åŸŸ**ï¼š
    *   è§†é¢‘ç†è§£/ç”Ÿæˆã€çº¯å›¾åƒç”Ÿæˆ/ä¿®å¤ã€å…·èº«æ™ºèƒ½/æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ã€3Dè§†è§‰ã€‚
    *   çº¯NLPçš„å®‰å…¨/å¯¹é½ï¼ˆSafety/Jailbreakï¼‰/æ”¿æ²»æ­£ç¡®ï¼Œé™¤éæ¶‰åŠâ€œè§†è§‰å¹»è§‰â€æ¶ˆé™¤ã€‚
3.  **å°è¯­ç§**ï¼šéä¸­è‹±çš„ç‰¹å®šè¯­è¨€æ•°æ®é›†æˆ–æ¨¡å‹ã€‚

### âœ… å…³æ³¨é¢†åŸŸä¸è¯„åˆ†æ ‡å‡†

#### 1. DIU æœ¬é¢˜ (High Priority) -> [7-10åˆ†]
*   **ä»»åŠ¡**ï¼šDocVQA, Layout Analysis, Table Recognition, VIE/KIE, OCR-free End-to-Endã€‚
*   **è¶‹åŠ¿**ï¼š
    *   **DeepSeek-OCR è·¯çº¿**ï¼š**Visual Token Compression (è§†è§‰å‹ç¼©)**ã€Visual Representation Learningã€‚
    *   **VLM for Doc**ï¼šä¸“ä¸ºæ–‡æ¡£è®¾è®¡çš„VLMæ¶æ„ã€è®­ç»ƒç­–ç•¥æˆ–é«˜è´¨é‡æ•°æ®é›†ã€‚
*   *æ³¨ï¼šDIUé¢†åŸŸå†…å³ä½¿æ˜¯ä¼ ç»Ÿæ–¹æ³•æˆ–æ•ˆç‡ä¼˜åŒ–ï¼Œä¹Ÿè¯·ä¿ç•™ï¼ˆç»™åŠæ ¼åˆ†ï¼‰ï¼Œå› ä¸ºåœˆå­å°ï¼Œä¸å®œæ¼æ‰ã€‚*

#### 2. å…³è”é¢†åŸŸçš„â€œå†›ç«åº“â€ (Tools & Methodology) -> [6-9åˆ†]
**ç­›é€‰æ ‡å‡†ï¼šè¿™ç¯‡ä¸Šæ¸¸è®ºæ–‡æå‡ºçš„æ–¹æ³•ï¼Œèƒ½å¦è¢«è¿ç§»æ¥è§£å†³DIUçš„ç—›ç‚¹ï¼Ÿ**
*   **ç—›ç‚¹åŒ…æ‹¬**ï¼šOCRå¹»è§‰ï¼ˆHallucinationï¼‰ã€ç»†ç²’åº¦å®šä½ï¼ˆGroundingï¼‰ã€é«˜åˆ†è¾¨ç‡å¤„ç†ã€å¤æ‚é€»è¾‘æ¨ç†ã€‚
*   **æœ‰ä»·å€¼çš„å·¥å…·**ï¼š
    *   **Inference Scaling / Test-time Compute**ï¼šCoTã€Searchã€Verificationæœºåˆ¶çš„**æºå¤´å·¥ä½œ**ã€‚
    *   **VLM Architecture**ï¼šèƒ½æ˜¾è‘—æå‡High-Resè¾“å…¥å¤„ç†èƒ½åŠ›æˆ–å¤šæ¨¡æ€å¯¹é½èƒ½åŠ›çš„æ¶æ„æ”¹è¿›ã€‚
    *   **Agent / Workflow**ï¼šèƒ½è§£å†³é•¿æ–‡æ¡£é˜…è¯»ã€å¤šæ­¥ä¿¡æ¯æ£€ç´¢è¿‡ç¨‹ä¸­è¿·å¤±é—®é¢˜çš„**Agentæ¶æ„è®¾è®¡**ï¼ˆè€ŒéæŸä¸ªå‚ç±»Agentåº”ç”¨ï¼‰ã€‚
    *   **Intervention / Steering**ï¼šæ¨ç†é˜¶æ®µçš„å¹²é¢„æˆ–å¼•å¯¼æŠ€æœ¯ï¼ˆä½œä¸ºä¸€ç§å¯èƒ½çš„å·¥å…·ï¼‰ã€‚

### âŒ è¿™æ˜¯ä¸€ä¸ªå‘è¡¨ä¿¡æ¯æå–ä»»åŠ¡
*   **Publicationå­—æ®µ**ï¼š**ä»…**å…è®¸ä» `comment` å­—æ®µæå–ï¼
*   **ä¸¥ç¦**å°† `category`ï¼ˆå¦‚ "cs.CV", "Computer Vision and Pattern Recognition"ï¼‰å½“ä½œå‘è¡¨ä¿¡æ¯ã€‚
*   å¦‚æœ `comment` ä¸ºç©ºæˆ–æœªæåŠä¼šè®®/æœŸåˆŠï¼Œå¿…é¡»è¿”å› "N/A"ã€‚

### ğŸ“ æ‰“åˆ†å‚è€ƒ (0-10)
*   **9-10 (Must Read)**ï¼šDIUçš„SOTAå·¥ä½œï¼›æˆ–è€…ä¸Šæ¸¸é¢†åŸŸå…·æœ‰**èŒƒå¼è½¬ç§»ï¼ˆParadigm Shiftï¼‰**æ„ä¹‰çš„åº•å±‚åˆ›æ–°ï¼ˆå¦‚Visual Token Compressionçš„å¼€å±±ä¹‹ä½œï¼Œæˆ–æ¨ç†Scalingçš„æ–°åŸç†ï¼‰ã€‚
*   **7-8 (Strong)**ï¼šæ‰å®çš„DIUå·¥ä½œï¼›æˆ–è€…èƒ½æ˜æ˜¾çœ‹åˆ°å¯¹DIUæœ‰è¿ç§»ä»·å€¼çš„ä¸Šæ¸¸æ–°æ–¹æ³•ï¼ˆå¦‚ä¸€ç§æ–°çš„VQAå»å¹»è§‰ç­–ç•¥ï¼‰ã€‚
*   **4-6 (Weak)**ï¼šDIUé¢†åŸŸçš„å¸¸è§„çŒæ°´ï¼›æˆ–è€…è™½æ˜¯ä¸Šæ¸¸çƒ­ç‚¹ä½†è¿ç§»åˆ°æ–‡æ¡£æå…¶å›°éš¾çš„å·¥ä½œã€‚
*   **0-3 (Reject)**ï¼šå¹³è¡Œåº”ç”¨ã€æ— å…³é¢†åŸŸã€å°è¯­ç§ã€‚

### âœ… ä»»åŠ¡æŒ‡ä»¤
è¯·æ ¹æ®ä»¥ä¸Šæ ‡å‡†è¯„ä¼°ã€‚
1.  **Score**: æ•´æ•°ã€‚
2.  **Title_zh**: ç¿»è¯‘æ ‡é¢˜ã€‚
3.  **Reason**: **ä¸­æ–‡**ã€‚
    *   **DIUè®ºæ–‡**ï¼šç®€è¿°å…¶é’ˆå¯¹ä»€ä¹ˆæ–‡æ¡£ä»»åŠ¡åšäº†ä»€ä¹ˆæ”¹è¿›ã€‚
    *   **ä¸Šæ¸¸è®ºæ–‡**ï¼š**æ ¸å¿ƒå¿…é¡»è§£é‡Šè¯¥æ–¹æ³•å¦‚ä½•è¿ç§»åˆ°DIUé¢†åŸŸ**ï¼ˆä¾‹å¦‚ï¼šâ€œè¯¥VLMåˆ†è¾¨ç‡å¤„ç†æ–¹æ³•å¯ç›´æ¥ç”¨äºæå‡æ–‡æ¡£ç»†ç²’åº¦è¯†åˆ«â€ï¼‰ã€‚
4.  **Summary**: ä¸­æ–‡æ€»ç»“ã€‚
5.  **Keywords**: 3-5ä¸ªå…³é”®è¯ã€‚
6.  **Publication**: æå–ä¼šè®®/æœŸåˆŠã€‚

è®ºæ–‡ä¿¡æ¯ï¼š
titleï¼š{title}
authorsï¼š{authors}
abstractï¼š{abstract}
commentï¼š{comment}
categoryï¼š{category}

å›å¤è¯·ç”¨jsonæ ¼å¼ï¼Œå¿…é¡»åªè¿”å›jsonï¼Œä¸è¦è¿”å›å…¶ä»–å†…å®¹ï¼š
"""

# JSON å“åº”æ¨¡æ¿
JSON_RESPONSE_TEMPLATE = """
{
  "score": x,
  "title_zh": "ä¸­æ–‡æ ‡é¢˜",
  "reason": "xxx",
  "summary": "xxx",
  "keywords": ["word1", "word2"],
  "publication": "xxx"
}
"""

def clean_json_response(response):
    """ä»LLMè¿”å›çš„å­—ç¬¦ä¸²ä¸­æå–JSONéƒ¨åˆ†"""
    start_index = response.find("{")
    end_index = response.rfind("}") + 1
    if start_index != -1 and end_index != -1:
        return response[start_index:end_index]
    return None

def main(input_file, output_file):
    client = OpenAI(
        api_key=API_KEY,
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    )

    # 1. è¯»å–è®ºæ–‡åˆ—è¡¨
    with open(input_file, 'r') as f:
        papers = json.load(f)
    
    if not papers:
        print("æ²¡æœ‰è®ºæ–‡éœ€è¦è¯„ä¼°ã€‚")
        return

    print(f"å‡†å¤‡è¯„ä¼° {len(papers)} ç¯‡è®ºæ–‡ï¼Œæ­£åœ¨æ„é€  Batch è¯·æ±‚æ–‡ä»¶...")

    # 2. æ„é€  JSONL æ•°æ® (Batch API çš„è¾“å…¥æ ¼å¼)
    jsonl_filename = "batch_tasks.jsonl"
    paper_map = {p['id']: p for p in papers} # æ–¹ä¾¿åç»­é€šè¿‡ ID æ‰¾å›è®ºæ–‡å¯¹è±¡
    
    with open(jsonl_filename, 'w') as f:
        for paper in papers:
            # æ„é€  Prompt
            prompt = PROMPT_TEMPLATE.format(
                title=paper['title'],
                authors=', '.join(paper['authors']) if isinstance(paper['authors'], list) else paper['authors'],
                abstract=paper['abstract'],
                comment=paper.get('comment', ''),
                category=paper['category'],
            ) + JSON_RESPONSE_TEMPLATE

            # æ„é€  Batch Request å¯¹è±¡
            # custom_id ä½¿ç”¨è®ºæ–‡ IDï¼Œæ–¹ä¾¿åç»­åŒ¹é…ç»“æœ
            request_obj = {
                "custom_id": paper['id'], 
                "method": "POST",
                "url": "/v1/chat/completions",
                "body": {
                    "model": MODEL_NAME,
                    "messages": [
                        {'role': 'system', 'content': 'You are a critical academic reviewer.'},
                        {'role': 'user', 'content': prompt}
                    ],
                    "temperature": 0.2
                }
            }
            f.write(json.dumps(request_obj) + '\n')

    # 3. ä¸Šä¼ æ–‡ä»¶
    print("æ­£åœ¨ä¸Šä¼  Batch æ–‡ä»¶...")
    batch_input_file = client.files.create(
        file=open(jsonl_filename, "rb"),
        purpose="batch"
    )
    print(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼ŒID: {batch_input_file.id}")

    # 4. åˆ›å»º Batch ä»»åŠ¡
    print("æ­£åœ¨åˆ›å»º Batch ä»»åŠ¡...")
    batch_job = client.batches.create(
        input_file_id=batch_input_file.id,
        endpoint="/v1/chat/completions",
        completion_window="24h", # é˜¿é‡Œäº‘ç›®å‰åªæ”¯æŒ 24h
        metadata={"description": "weekly_arxiv_evaluation"}
    )
    print(f"Batch ä»»åŠ¡åˆ›å»ºæˆåŠŸï¼ŒJob ID: {batch_job.id}")

    # 5. è½®è¯¢ç­‰å¾…ä»»åŠ¡å®Œæˆ
    print("å¼€å§‹è½®è¯¢ä»»åŠ¡çŠ¶æ€ (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿåˆ°å‡ å°æ—¶)...")
    start_time = time.time()
    
    while True:
        # è·å–ä»»åŠ¡æœ€æ–°çŠ¶æ€
        batch_job = client.batches.retrieve(batch_job.id)
        status = batch_job.status
        print(f"å½“å‰çŠ¶æ€: {status} (å·²è€—æ—¶: {int(time.time() - start_time)}s)")

        if status == 'completed':
            print("ä»»åŠ¡å®Œæˆï¼")
            break
        elif status in ['failed', 'expired', 'cancelled']:
            print(f"ä»»åŠ¡å¤±è´¥ï¼ŒçŠ¶æ€: {status}")
            # æ‰“å°é”™è¯¯ä¿¡æ¯
            if batch_job.errors:
                print(batch_job.errors)
            return
        
        # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
        if time.time() - start_time > MAX_WAIT_TIME:
            print("é”™è¯¯ï¼šç­‰å¾…è¶…æ—¶ï¼Œè„šæœ¬ç»ˆæ­¢ã€‚")
            return

        time.sleep(POLL_INTERVAL)

    # 6. ä¸‹è½½å¹¶å¤„ç†ç»“æœ
    if batch_job.output_file_id:
        print("æ­£åœ¨ä¸‹è½½ç»“æœæ–‡ä»¶...")
        file_response = client.files.content(batch_job.output_file_id)
        result_content = file_response.text
        
        print("æ­£åœ¨è§£æç»“æœå¹¶å†™å…¥æœ€ç»ˆ JSON...")
        
        # è§£æ JSONL ç»“æœ
        for line in result_content.splitlines():
            if not line.strip(): continue
            
            result = json.loads(line)
            custom_id = result['custom_id']
            
            # æ‰¾åˆ°å¯¹åº”çš„åŸå§‹è®ºæ–‡å¯¹è±¡
            if custom_id in paper_map:
                paper = paper_map[custom_id]
                
                # è·å– LLM çš„å“åº”å†…å®¹
                # æ³¨æ„ï¼šBatch API çš„è¿”å›ç»“æ„ç¨å¾®æ·±ä¸€ç‚¹
                try:
                    print(result['response']['body'])
                    choice = result['response']['body']['choices'][0]
                    content = choice['message']['content']
                    
                    # ä½¿ç”¨ä¹‹å‰çš„æ¸…æ´—å‡½æ•°è§£æ JSON
                    cleaned_json = clean_json_response(content)
                    if cleaned_json:
                        try:
                            eval_data = json.loads(cleaned_json)
                            # æ›´æ–°å­—æ®µ
                            paper['score'] = eval_data.get('score', 0)
                            paper['title_zh'] = eval_data.get('title_zh', '')
                            paper['reason'] = eval_data.get('reason', 'N/A')
                            paper['summary'] = eval_data.get('summary', 'N/A')
                            paper['keywords'] = eval_data.get('keywords', [])
                            paper['publication'] = eval_data.get('publication', 'N/A')
                        except json.JSONDecodeError:
                            print(f"ID {custom_id} JSON è§£æå¤±è´¥: {cleaned_json}")
                    else:
                        print(f"ID {custom_id} æœªæ‰¾åˆ°æœ‰æ•ˆ JSON å†…å®¹")
                        
                except Exception as e:
                    print(f"ID {custom_id} å¤„ç†å“åº”æ—¶å‡ºé”™: {e}")
            else:
                print(f"è­¦å‘Šï¼šæ”¶åˆ°æœªçŸ¥ custom_id {custom_id} çš„ç»“æœ")

        # å†™å…¥æœ€ç»ˆç»“æœ
        with open(output_file, 'w') as f:
            json.dump(papers, f, indent=2, ensure_ascii=False)
        
        print(f"å¤„ç†å®Œæˆï¼ç»“æœå·²å†™å…¥ {output_file}")
    else:
        print("ä»»åŠ¡å®Œæˆä½†æ²¡æœ‰ output_file_idï¼Œå¯èƒ½å…¨éƒ¨è¯·æ±‚éƒ½å¤±è´¥äº†ã€‚")

if __name__ == "__main__":
    main("target/latest_papers.json", "target/evaluated_papers.json")
