import os
import json
from openai import OpenAI

# å¡«å†™APIçš„å¯†é’¥
API_KEY = os.getenv("API_KEY")

# è‡ªå®šä¹‰çš„æç¤ºæ¨¡æ¿
PROMPT_TEMPLATE = """
æˆ‘æ˜¯ä¸€åäººå·¥æ™ºèƒ½æ–¹å‘çš„ç ”ç©¶ç”Ÿï¼Œæ ¸å¿ƒç ”ç©¶é¢†åŸŸæ˜¯ **æ–‡æ¡£å›¾åƒç†è§£ï¼ˆDIU / DocVQAï¼‰**ã€‚
æˆ‘çš„ç›®æ ‡æ˜¯åˆ©ç”¨ **VLM (Multimodal LLM)** æŠ€æœ¯è§£å†³æ–‡æ¡£ç†è§£ä¸­çš„æ ¸å¿ƒç—›ç‚¹ï¼ˆå¦‚OCRå¹»è§‰ã€å¯†é›†æ–‡æœ¬ã€å¤æ‚æ’ç‰ˆã€é•¿æ–‡æ¡£æ¨ç†ï¼‰ã€‚

è¯·æ‹…ä»»ä¸€å**æŒ‘å‰”çš„å®¡ç¨¿äºº**ï¼Œå¸®æˆ‘ç­›é€‰è®ºæ–‡ã€‚
**åŸåˆ™ï¼šä¸æ‹˜æ³¥äºç‰¹å®šæŠ€æœ¯è·¯çº¿ï¼ˆå¦‚å¿…é¡»æ˜¯Agentæˆ–å¿…é¡»æ˜¯Interventionï¼‰ï¼Œåªè¦èƒ½æå‡DIUæ€§èƒ½çš„åº•å±‚æ–¹æ³•éƒ½å€¼å¾—å…³æ³¨ï¼›ä½†åšå†³æŠµåˆ¶æ— è¥å…»çš„â€œå¹³è¡Œåº”ç”¨â€ã€‚**

### ğŸ›‘ è´Ÿé¢æ¸…å•ï¼ˆç›´æ¥æ‰“0-3åˆ†ï¼‰
**åªè¦å‘½ä¸­ä»¥ä¸‹ä»»æ„ä¸€ç‚¹ï¼Œæ— éœ€ç•™æƒ…ï¼Œç›´æ¥ä½åˆ†ï¼š**
1.  **å¹³è¡Œä¸‹æ¸¸åº”ç”¨ï¼ˆWrapper/Applicationï¼‰**ï¼š
    *   ä¾‹å¦‚ï¼šâ€œç”¨LLMè¿›è¡Œé‡‘èæŠ¥è¡¨åˆ†æâ€ã€â€œåŸºäºRAGçš„æ³•å¾‹æ–‡ä¹¦åŠ©æ‰‹â€ã€â€œåŒ»ç–—ç—…å†ç»“æ„åŒ–â€ã€‚
    *   **ç†ç”±**ï¼šè¿™äº›åªæ˜¯æŠŠç°æœ‰æŠ€æœ¯ç”¨åœ¨ç‰¹å®šæ•°æ®ä¸Šï¼Œæ²¡æœ‰æ–¹æ³•è®ºåˆ›æ–°ã€‚æˆ‘åªè¦æå‡ºæŠ€æœ¯æºå¤´çš„è®ºæ–‡ã€‚
2.  **æ— å…³é¢†åŸŸ**ï¼š
    *   è§†é¢‘ç†è§£/ç”Ÿæˆã€çº¯å›¾åƒç”Ÿæˆ/ä¿®å¤ã€å…·èº«æ™ºèƒ½/æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ã€3Dè§†è§‰ã€‚
    *   çº¯NLPçš„å®‰å…¨/å¯¹é½ï¼ˆSafety/Jailbreakï¼‰/æ”¿æ²»æ­£ç¡®ï¼Œé™¤éæ¶‰åŠâ€œè§†è§‰å¹»è§‰â€æ¶ˆé™¤ã€‚
3.  **å°è¯­ç§**ï¼šéä¸­è‹±çš„ç‰¹å®šè¯­è¨€æ•°æ®é›†æˆ–æ¨¡å‹ã€‚

### âœ… å…³æ³¨é¢†åŸŸä¸è¯„åˆ†æ ‡å‡†

#### 1. DIU æœ¬é¢˜ (High Priority) -> [7-10åˆ†]
*   **ä»»åŠ¡**ï¼šDocVQA, Layout Analysis, Table Recognition, VIE/KIE, OCR-free End-to-Endã€‚
*   **è¶‹åŠ¿**ï¼š
    *   **DeepSeek-OCR è·¯çº¿**ï¼š**Visual Token Compression (è§†è§‰å‹ç¼©)**ã€Visual Representation Learningã€‚
    *   **VLM for Doc**ï¼šä¸“ä¸ºæ–‡æ¡£è®¾è®¡çš„VLMæ¶æ„ã€è®­ç»ƒç­–ç•¥æˆ–é«˜è´¨é‡æ•°æ®é›†ã€‚
*   *æ³¨ï¼šDIUé¢†åŸŸå†…å³ä½¿æ˜¯ä¼ ç»Ÿæ–¹æ³•æˆ–æ•ˆç‡ä¼˜åŒ–ï¼Œä¹Ÿè¯·ä¿ç•™ï¼ˆç»™åŠæ ¼åˆ†ï¼‰ï¼Œå› ä¸ºåœˆå­å°ï¼Œä¸å®œæ¼æ‰ã€‚*

#### 2. å…³è”é¢†åŸŸçš„â€œå†›ç«åº“â€ (Tools & Methodology) -> [6-9åˆ†]
**ç­›é€‰æ ‡å‡†ï¼šè¿™ç¯‡ä¸Šæ¸¸è®ºæ–‡æå‡ºçš„æ–¹æ³•ï¼Œèƒ½å¦è¢«è¿ç§»æ¥è§£å†³DIUçš„ç—›ç‚¹ï¼Ÿ**
*   **ç—›ç‚¹åŒ…æ‹¬**ï¼šOCRå¹»è§‰ï¼ˆHallucinationï¼‰ã€ç»†ç²’åº¦å®šä½ï¼ˆGroundingï¼‰ã€é«˜åˆ†è¾¨ç‡å¤„ç†ã€å¤æ‚é€»è¾‘æ¨ç†ã€‚
*   **æœ‰ä»·å€¼çš„å·¥å…·**ï¼š
    *   **Inference Scaling / Test-time Compute**ï¼šCoTã€Searchã€Verificationæœºåˆ¶çš„**æºå¤´å·¥ä½œ**ã€‚
    *   **VLM Architecture**ï¼šèƒ½æ˜¾è‘—æå‡High-Resè¾“å…¥å¤„ç†èƒ½åŠ›æˆ–å¤šæ¨¡æ€å¯¹é½èƒ½åŠ›çš„æ¶æ„æ”¹è¿›ã€‚
    *   **Agent / Workflow**ï¼šèƒ½è§£å†³é•¿æ–‡æ¡£é˜…è¯»ã€å¤šæ­¥ä¿¡æ¯æ£€ç´¢è¿‡ç¨‹ä¸­è¿·å¤±é—®é¢˜çš„**Agentæ¶æ„è®¾è®¡**ï¼ˆè€ŒéæŸä¸ªå‚ç±»Agentåº”ç”¨ï¼‰ã€‚
    *   **Intervention / Steering**ï¼šæ¨ç†é˜¶æ®µçš„å¹²é¢„æˆ–å¼•å¯¼æŠ€æœ¯ï¼ˆä½œä¸ºä¸€ç§å¯èƒ½çš„å·¥å…·ï¼‰ã€‚

### âŒ è¿™æ˜¯ä¸€ä¸ªå‘è¡¨ä¿¡æ¯æå–ä»»åŠ¡
*   **Publicationå­—æ®µ**ï¼š**ä»…**å…è®¸ä» `comment` å­—æ®µæå–ï¼
*   **ä¸¥ç¦**å°† `category`ï¼ˆå¦‚ "cs.CV", "Computer Vision and Pattern Recognition"ï¼‰å½“ä½œå‘è¡¨ä¿¡æ¯ã€‚
*   å¦‚æœ `comment` ä¸ºç©ºæˆ–æœªæåŠä¼šè®®/æœŸåˆŠï¼Œå¿…é¡»è¿”å› "N/A"ã€‚

### ğŸ“ æ‰“åˆ†å‚è€ƒ (0-10)
*   **9-10 (Must Read)**ï¼šDIUçš„SOTAå·¥ä½œï¼›æˆ–è€…ä¸Šæ¸¸é¢†åŸŸå…·æœ‰**èŒƒå¼è½¬ç§»ï¼ˆParadigm Shiftï¼‰**æ„ä¹‰çš„åº•å±‚åˆ›æ–°ï¼ˆå¦‚Visual Token Compressionçš„å¼€å±±ä¹‹ä½œï¼Œæˆ–æ¨ç†Scalingçš„æ–°åŸç†ï¼‰ã€‚
*   **7-8 (Strong)**ï¼šæ‰å®çš„DIUå·¥ä½œï¼›æˆ–è€…èƒ½æ˜æ˜¾çœ‹åˆ°å¯¹DIUæœ‰è¿ç§»ä»·å€¼çš„ä¸Šæ¸¸æ–°æ–¹æ³•ï¼ˆå¦‚ä¸€ç§æ–°çš„VQAå»å¹»è§‰ç­–ç•¥ï¼‰ã€‚
*   **4-6 (Weak)**ï¼šDIUé¢†åŸŸçš„å¸¸è§„çŒæ°´ï¼›æˆ–è€…è™½æ˜¯ä¸Šæ¸¸çƒ­ç‚¹ä½†è¿ç§»åˆ°æ–‡æ¡£æå…¶å›°éš¾çš„å·¥ä½œã€‚
*   **0-3 (Reject)**ï¼šå¹³è¡Œåº”ç”¨ã€æ— å…³é¢†åŸŸã€å°è¯­ç§ã€‚

### âœ… ä»»åŠ¡æŒ‡ä»¤
è¯·æ ¹æ®ä»¥ä¸Šæ ‡å‡†è¯„ä¼°ã€‚
1.  **Score**: æ•´æ•°ã€‚
2.  **Title_zh**: ç¿»è¯‘æ ‡é¢˜ã€‚
3.  **Reason**: **ä¸­æ–‡**ã€‚
    *   **DIUè®ºæ–‡**ï¼šç®€è¿°å…¶é’ˆå¯¹ä»€ä¹ˆæ–‡æ¡£ä»»åŠ¡åšäº†ä»€ä¹ˆæ”¹è¿›ã€‚
    *   **ä¸Šæ¸¸è®ºæ–‡**ï¼š**æ ¸å¿ƒå¿…é¡»è§£é‡Šè¯¥æ–¹æ³•å¦‚ä½•è¿ç§»åˆ°DIUé¢†åŸŸ**ï¼ˆä¾‹å¦‚ï¼šâ€œè¯¥VLMåˆ†è¾¨ç‡å¤„ç†æ–¹æ³•å¯ç›´æ¥ç”¨äºæå‡æ–‡æ¡£ç»†ç²’åº¦è¯†åˆ«â€ï¼‰ã€‚
4.  **Summary**: ä¸­æ–‡æ€»ç»“ã€‚
5.  **Keywords**: 3-5ä¸ªå…³é”®è¯ã€‚
6.  **Publication**: æå–ä¼šè®®/æœŸåˆŠã€‚

è®ºæ–‡ä¿¡æ¯ï¼š
titleï¼š{title}
authorsï¼š{authors}
abstractï¼š{abstract}
commentï¼š{comment}
categoryï¼š{category}

å›å¤è¯·ç”¨jsonæ ¼å¼ï¼Œå¿…é¡»åªè¿”å›jsonï¼Œä¸è¦è¿”å›å…¶ä»–å†…å®¹ï¼š
"""

# JSON å“åº”æ¨¡æ¿
JSON_RESPONSE_TEMPLATE = """
{
  "score": x,
  "title_zh": "ä¸­æ–‡æ ‡é¢˜",
  "reason": "xxx",
  "summary": "xxx",
  "keywords": ["word1", "word2"],
  "publication": "xxx"
}
"""

def call_qwen_api(prompt):
    try:
        client = OpenAI(
            api_key=API_KEY,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        )
        completion = client.chat.completions.create(
            model="qwen-flash", 
            messages=[
                {'role': 'system', 'content': 'You are a helpful assistant.'},
                {'role': 'user', 'content': prompt}
            ]
        )
        print(completion)
        return completion.choices[0].message.content
    except Exception as e:
        print(f"Error: {e}")
        return None

def clean_json_response(response):
    start_index = response.find("{")
    end_index = response.rfind("}") + 1
    if start_index != -1 and end_index != -1:
        return response[start_index:end_index]
    return None

def evaluate_papers(input_file, output_file):
    with open(input_file, 'r') as f:
        papers = json.load(f)

    print(f"æ­£åœ¨æ ¹æ®å†…å®¹è¯„ä¼° {len(papers)} ç¯‡è®ºæ–‡...")

    for paper in papers:
        prompt = PROMPT_TEMPLATE.format(
            title=paper['title'],
            authors=', '.join(paper['authors']) if isinstance(paper['authors'], list) else paper['authors'],
            abstract=paper['abstract'],
            comment=paper.get('comment', ''),
            category=paper['category'],
        ) + JSON_RESPONSE_TEMPLATE
        
        # print(f"Evaluating: {paper['title']}")
        res = call_qwen_api(prompt)
        
        if res:
            cleaned_res = clean_json_response(res)
            if cleaned_res:
                try:
                    response = json.loads(cleaned_res)
                    paper['score'] = response.get('score', 0)
                    paper['reason'] = response.get('reason', 'N/A')
                    paper['summary'] = response.get('summary', 'N/A')
                    paper['keywords'] = response.get('keywords', [])
                    paper['title_zh'] = response.get('title_zh', '')
                    paper['publication'] = response.get('publication', 'N/A')
                except json.JSONDecodeError:
                    print(f"JSONè§£æå¤±è´¥: {cleaned_res}")
            else:
                print("æœªæ‰¾åˆ°JSON")
        else:
            print("APIè°ƒç”¨å¤±è´¥")

    with open(output_file, 'w') as f:
        json.dump(papers, f, indent=2, ensure_ascii=False)

if __name__ == "__main__":
    evaluate_papers("target/latest_papers.json", "target/evaluated_papers.json")
