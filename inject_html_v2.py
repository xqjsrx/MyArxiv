import json
import re
from bs4 import BeautifulSoup

# è¯»å–æ–‡ä»¶
with open("target/evaluated_papers.json", 'r') as f:
    evaluated_papers = json.load(f)

with open("target/index.html", 'r') as f:
    html_content = f.read()

soup = BeautifulSoup(html_content, 'html.parser')

# è¿‡æ»¤ä¸æ’åº
scored_papers = [p for p in evaluated_papers if 'score' in p and isinstance(p['score'], int)]
scored_papers.sort(key=lambda x: x['score'], reverse=True)

# è¾…åŠ©å‡½æ•°ï¼šåˆ›å»ºç»Ÿä¸€æ ¼å¼çš„ 'Label + Content' è¡Œ
def create_row_with_label(soup, label_text, content_text):
    if not content_text or content_text == "N/A":
        return None
        
    div = soup.new_tag('div', **{'class': 'article-summary-box-inner', 'style': 'margin-top: 6px;'})
    
    # Label: ä½¿ç”¨åŸç”Ÿ class="chip"
    label = soup.new_tag('span', **{'class': 'chip'})
    label.string = label_text
    div.append(label)
    
    # Content: ä¸åŠ  styleï¼Œè·Ÿéšä¸»é¢˜
    content = soup.new_tag('span', **{'style': 'margin-left: 8px;'})
    content.string = str(content_text)
    div.append(content)
    
    return div

# ----------------- æ„å»ºé¡µé¢ -----------------

if scored_papers:
    # å®¹å™¨è¾¹æ¡†é¢œè‰²æœ€å¥½è¿˜æ˜¯æŒ‡å®šä¸€ä¸‹ï¼Œä¸ç„¶å¯èƒ½çœ‹ä¸å‡ºæ¥ï¼Œè¿™é‡Œç”¨äº† var(--nord08) å³åŸæœ¬çš„ä¸»é¢˜è‰²
    top_section = soup.new_tag('section', **{'class': 'day-container', 'style': 'margin-top: 20px; border: 2px solid var(--nord08);'})
    
    # å¤´éƒ¨ï¼šé¢œè‰²è·Ÿéš .date ç±»
    header_div = soup.new_tag('div', **{'class': 'date', 'style': 'padding-bottom: 15px; border-bottom: 1px solid var(--nord04); margin-bottom: 15px;'})
    header_div.string = f"ğŸ† Weekly Top Picks ({len(scored_papers)} Papers)"
    top_section.append(header_div)

    for paper in scored_papers:
        article = soup.new_tag('article', **{'style': 'margin-bottom: 20px; padding-bottom: 20px; border-bottom: 1px dashed var(--nord03);'})
        # é»˜è®¤å±•å¼€
        details = soup.new_tag('details', **{'class': 'article-expander', 'open': 'true'})
        
        # === ç¬¬1è¡Œï¼šScore | Title | Publication ===
        summary_tag = soup.new_tag('summary', **{'class': 'article-expander-title', 'style': 'display: flex; align-items: baseline; flex-wrap: wrap;'})
        
        # Score (ä½¿ç”¨ chip æ ·å¼ï¼Œæ‰‹åŠ¨åŠ ä¸ªèƒŒæ™¯è‰²åŒºåˆ†ï¼Œæˆ–è€…ç›´æ¥ç”¨é»˜è®¤ chip)
        # ä¸ºäº†çªå‡ºåˆ†æ•°ï¼Œè¿™é‡Œä¿ç•™ä¸€ç‚¹ç‚¹è‡ªå®šä¹‰èƒŒæ™¯ï¼Œä¹Ÿå¯ä»¥åˆ æ‰ style å˜æˆé»˜è®¤ chip
        score_span = soup.new_tag('span', **{'class': 'chip', 'style': 'background: var(--nord0B); color: white; margin-right: 8px;'})
        score_span.string = str(paper['score'])
        summary_tag.append(score_span)
        
        # Title
        title_span = soup.new_tag('span', **{'style': 'font-size: 1.1em; margin-right: 10px; font-weight: bold;'})
        title_span.string = paper['title']
        summary_tag.append(title_span)
        
        # Publication (Extracted by AI)
        if paper.get('publication') and paper['publication'] != "N/A":
            # ä½¿ç”¨é»˜è®¤ chip æ ·å¼
            pub_span = soup.new_tag('span', **{'class': 'chip'})
            pub_span.string = paper['publication']
            summary_tag.append(pub_span)
            
        details.append(summary_tag)

        # === ç¬¬2è¡Œï¼šLinks | Authors ===
        # ä½¿ç”¨ article-authors ç±»ï¼Œä¿æŒåŸç”Ÿé¢œè‰²
        meta_div = soup.new_tag('div', **{'class': 'article-authors', 'style': 'margin: 5px 0; display: flex; align-items: center;'})
        
        # Link Logic
        abs_link = paper['id']
        pdf_link = abs_link.replace('/abs/', '/pdf/')
        pdf_link = re.sub(r'v\d+$', '', pdf_link)

        # Icons
        link_a = soup.new_tag('a', href=abs_link, target="_blank", **{'style': 'margin-right: 10px; text-decoration: none;'})
        link_i = soup.new_tag('i', **{'class': 'ri-links-line'}) # åŸç”Ÿå›¾æ ‡
        link_a.append(link_i)
        meta_div.append(link_a)
        
        pdf_a = soup.new_tag('a', href=pdf_link, target="_blank", **{'style': 'margin-right: 15px; text-decoration: none;'})
        pdf_i = soup.new_tag('i', **{'class': 'ri-file-pdf-line'}) # ä½¿ç”¨ RemixIcon çš„ PDF å›¾æ ‡
        pdf_a.append(pdf_i)
        meta_div.append(pdf_a)

        # Authors (ä¸åŠ  styleï¼Œç»§æ‰¿ article-authors çš„é¢œè‰²)
        authors_text = soup.new_tag('span')
        if isinstance(paper['authors'], list):
            authors_text.string = ", ".join(paper['authors'])
        else:
            authors_text.string = paper['authors']
        meta_div.append(authors_text)
        
        details.append(meta_div)

        # === ç¬¬3è¡Œï¼šTitle Translation ===
        if paper.get('title_zh'):
            trans_row = create_row_with_label(soup, "Title CN", paper['title_zh'])
            if trans_row: details.append(trans_row)

        # === ç¬¬4è¡Œï¼šAI Keywords ===
        keywords = paper.get('keywords', [])
        if keywords:
            if isinstance(keywords, list):
                keywords_str = " Â· ".join(keywords)
            else:
                keywords_str = keywords
            kw_row = create_row_with_label(soup, "AI Keywords", keywords_str)
            if kw_row: details.append(kw_row)

        # === ç¬¬5è¡Œï¼šAI Summary ===
        sum_row = create_row_with_label(soup, "AI Summary", paper.get('summary', ''))
        if sum_row: details.append(sum_row)

        # === ç¬¬6è¡Œï¼šAI Reason ===
        reason_row = create_row_with_label(soup, "AI Reason", paper.get('reason', ''))
        if reason_row: details.append(reason_row)

        # === ç¬¬7è¡Œï¼šOriginal Abstract ===
        abs_row = create_row_with_label(soup, "Original Abstract", paper.get('abstract', ''))
        if abs_row: details.append(abs_row)

        # === ç¬¬8è¡Œï¼šRaw Comment ===
        if paper.get('comment'):
            com_row = create_row_with_label(soup, "Raw Comment", paper['comment'])
            if com_row: details.append(com_row)

        # === ç¬¬9è¡Œï¼šCategories ===
        cat_row = create_row_with_label(soup, "Categories", paper.get('category', ''))
        if cat_row: details.append(cat_row)

        article.append(details)
        top_section.append(article)

    # æ’å…¥ Header
    header_container = soup.find('section', class_='header-container')
    if header_container:
        header_container.insert_after(top_section)
    else:
        soup.body.insert(0, top_section)

# å†™å›
with open("target/index.html", 'w') as f:
    f.write(str(soup.prettify()))

print("HTML injection complete.")
