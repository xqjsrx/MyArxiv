import json
import re
from bs4 import BeautifulSoup

# è¯»å–æ–‡ä»¶
with open("target/evaluated_papers.json", 'r') as f:
    evaluated_papers = json.load(f)

with open("target/index.html", 'r') as f:
    html_content = f.read()

soup = BeautifulSoup(html_content, 'html.parser')

# è¿‡æ»¤ä¸æ’åº
scored_papers = [p for p in evaluated_papers if 'score' in p and isinstance(p['score'], int)]
scored_papers.sort(key=lambda x: x['score'], reverse=True)

def create_row_with_label(soup, label_text, content_text):
    """
    åˆ›å»º 'Label + Content' è¡Œ
    ä½¿ç”¨ class="chip" ä¿æŒä¸ä¸»é¢˜ä¸€è‡´çš„é…è‰²
    """
    if not content_text or content_text == "N/A":
        return None
        
    div = soup.new_tag('div', **{'class': 'article-summary-box-inner', 'style': 'margin-top: 6px;'})
    
    # Label (ä½¿ç”¨åŸç”Ÿ chip æ ·å¼)
    label = soup.new_tag('span', **{'class': 'chip'})
    label.string = label_text
    div.append(label)
    
    # Content (ä¸è®¾ç½®é¢œè‰²ï¼Œç»§æ‰¿ body é¢œè‰²ï¼ŒåªåŠ ä¸€ä¸ªå·¦è¾¹è·)
    content = soup.new_tag('span', **{'style': 'margin-left: 8px;'})
    content.string = str(content_text)
    div.append(content)
    
    return div

if scored_papers:
    # å¤–å±‚å®¹å™¨
    top_section = soup.new_tag('section', **{'class': 'day-container', 'style': 'margin-top: 20px; border: 2px solid var(--nord08);'})
    
    # é¡¶éƒ¨æ ‡é¢˜
    header_div = soup.new_tag('div', **{'class': 'date', 'style': 'color: var(--nord08); padding-bottom: 15px; border-bottom: 1px solid var(--nord04); margin-bottom: 15px;'})
    header_div.string = f"ğŸ† Weekly Top Picks ({len(scored_papers)} Papers)"
    top_section.append(header_div)

    for paper in scored_papers:
        article = soup.new_tag('article', **{'style': 'margin-bottom: 20px; padding-bottom: 20px; border-bottom: 1px dashed var(--nord03);'})
        details = soup.new_tag('details', **{'class': 'article-expander', 'open': 'true'})
        
        # === ç¬¬1è¡Œï¼šåˆ†æ•° | è‹±æ–‡æ ‡é¢˜ | ä¸­æ–‡æ ‡é¢˜ | å‘è¡¨ä¿¡æ¯ ===
        summary_tag = soup.new_tag('summary', **{'class': 'article-expander-title', 'style': 'display: block; line-height: 1.6;'})
        
        # 1. Score Label
        score_span = soup.new_tag('span', **{'class': 'chip'})
        score_span.string = str(paper['score'])
        summary_tag.append(score_span)
        
        # 2. English Title
        title_span = soup.new_tag('span', **{'style': 'font-size: 1.1em; margin: 0 8px; font-weight: bold;'})
        title_span.string = paper['title']
        summary_tag.append(title_span)

        # 3. Chinese Title (Label + Text)
        if paper.get('title_zh'):
            zh_label = soup.new_tag('span', **{'class': 'chip'})
            zh_label.string = "ä¸­æ–‡æ ‡é¢˜"
            summary_tag.append(zh_label)
            
            zh_text = soup.new_tag('span', **{'style': 'margin: 0 8px; font-weight: normal; font-size: 0.95em;'})
            zh_text.string = paper['title_zh']
            summary_tag.append(zh_text)

        # 4. Publication (å¦‚æœæœ‰)
        if paper.get('publication') and paper['publication'] != "N/A":
            pub_span = soup.new_tag('span', **{'class': 'chip'})
            pub_span.string = paper['publication']
            summary_tag.append(pub_span)
            
        details.append(summary_tag)

        # === ç¬¬2è¡Œï¼šLinks (ABS/PDF) ===
        # ä½¿ç”¨ class="article-authors" ä¿æŒé—´è·ä¹ æƒ¯ï¼Œä½†é‡Œé¢æ”¾ chip
        link_div = soup.new_tag('div', **{'class': 'article-authors', 'style': 'margin-top: 5px;'})
        
        # æ„é€  PDF é“¾æ¥
        abs_link = paper['id']
        pdf_link = abs_link.replace('/abs/', '/pdf/')
        pdf_link = re.sub(r'v\d+$', '', pdf_link)

        # ABS Chip
        abs_a = soup.new_tag('a', href=abs_link, target="_blank", **{'class': 'chip', 'style': 'text-decoration: none; margin-right: 10px;'})
        abs_a.string = "ABS"
        link_div.append(abs_a)
        
        # PDF Chip
        pdf_a = soup.new_tag('a', href=pdf_link, target="_blank", **{'class': 'chip', 'style': 'text-decoration: none;'})
        pdf_a.string = "PDF" 
        link_div.append(pdf_a)
        
        details.append(link_div)

        # === ç¬¬3è¡Œï¼šAuthors ===
        # ä½œè€…ä¹Ÿç”¨ chip æ ·å¼åŒ…è£¹ Label å—ï¼Ÿä¸ï¼Œé€šå¸¸ä½œè€…åˆ—è¡¨ç›´æ¥æ˜¾ç¤ºã€‚
        # ä½ è¯´â€œä½œè€…ä¹Ÿç”¨åŸæ¥çš„é¢œè‰²â€ï¼ŒåŸæ¥çš„ä½œè€…æ˜¯ç›´æ¥æ˜¾ç¤ºçš„æ–‡æœ¬ã€‚
        authors_div = soup.new_tag('div', **{'class': 'article-authors', 'style': 'margin-bottom: 5px;'})
        authors_icon = soup.new_tag('i', **{'class': 'ri-user-3-line', 'style': 'margin-right: 5px;'}) # åŠ ä¸ªå°å›¾æ ‡ç¾åŒ–
        authors_div.append(authors_icon)
        
        authors_text = soup.new_tag('span') # ä¸åŠ  styleï¼Œç»§æ‰¿é»˜è®¤é¢œè‰²
        if isinstance(paper['authors'], list):
            authors_text.string = ", ".join(paper['authors'])
        else:
            authors_text.string = paper['authors']
        authors_div.append(authors_text)
        details.append(authors_div)

        # === ç¬¬4è¡Œï¼šAI Keywords ===
        keywords = paper.get('keywords', [])
        if keywords:
            if isinstance(keywords, list):
                keywords_str = " Â· ".join(keywords)
            else:
                keywords_str = keywords
            kw_row = create_row_with_label(soup, "AI Keywords", keywords_str)
            if kw_row: details.append(kw_row)

        # === ç¬¬5è¡Œï¼šAI Summary ===
        sum_row = create_row_with_label(soup, "AI Summary", paper.get('summary', ''))
        if sum_row: details.append(sum_row)

        # === ç¬¬6è¡Œï¼šAI Reason ===
        reason_row = create_row_with_label(soup, "AI Reason", paper.get('reason', ''))
        if reason_row: details.append(reason_row)

        # === ç¬¬7è¡Œï¼šOriginal Abstract ===
        abs_row = create_row_with_label(soup, "Original Abstract", paper.get('abstract', ''))
        if abs_row: details.append(abs_row)

        # === ç¬¬8è¡Œï¼šComment (Raw) ===
        if paper.get('comment'):
            com_row = create_row_with_label(soup, "Comment", paper['comment'])
            if com_row: details.append(com_row)

        # === ç¬¬9è¡Œï¼šCategories ===
        cat_row = create_row_with_label(soup, "Categories", paper.get('category', ''))
        if cat_row: details.append(cat_row)

        article.append(details)
        top_section.append(article)

    # æ’å…¥ Header
    header_container = soup.find('section', class_='header-container')
    if header_container:
        header_container.insert_after(top_section)
    else:
        soup.body.insert(0, top_section)

# å†™å›
with open("target/index.html", 'w') as f:
    f.write(str(soup.prettify()))

print("HTML injection complete: Original Theme Colors & New Layout.")
