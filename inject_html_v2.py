import json
import re
from bs4 import BeautifulSoup

# è¯»å–æ–‡ä»¶
with open("target/evaluated_papers.json", 'r') as f:
    evaluated_papers = json.load(f)

with open("target/index.html", 'r') as f:
    html_content = f.read()

soup = BeautifulSoup(html_content, 'html.parser')

# è¿‡æ»¤ä¸æ’åº
scored_papers = [p for p in evaluated_papers if 'score' in p and isinstance(p['score'], int)]
scored_papers.sort(key=lambda x: x['score'], reverse=True)

# ----------------- æ ·å¼é…ç½® (å…³é”®è°ƒæ•´) -----------------

# 1. æ¯ä¸€è¡Œçš„å®¹å™¨ï¼šFlexå¸ƒå±€ï¼Œåº•éƒ¨è™šçº¿ï¼Œå†…è¾¹è·
STYLE_ROW = "display: flex; align-items: flex-start; padding: 8px 0; border-bottom: 1px dashed var(--nord04);"

# 2. æ ‡ç­¾æ ·å¼ï¼šç»§æ‰¿ .chip çš„é¢œè‰²ï¼Œä½†å¼ºåˆ¶å›ºå®šå®½åº¦ (130px)ï¼Œå±…ä¸­å¯¹é½ï¼Œé˜²æ­¢è¢«å‹ç¼©
# flex-shrink: 0 ä¿è¯æ ‡ç­¾ä¸ä¼šå› ä¸ºæ­£æ–‡å¤ªé•¿è€Œè¢«æŒ¤æ‰
STYLE_LABEL_FIXED = "class: chip; width: 130px; text-align: center; flex-shrink: 0; margin-right: 15px; display: block;"

# 3. æ­£æ–‡å®¹å™¨ï¼šå æ®å‰©ä½™ç©ºé—´
STYLE_CONTENT = "flex-grow: 1; line-height: 1.6; font-size: 0.95em;"

def create_styled_row(soup, label_text, content_text, is_last=False):
    """åˆ›å»ºå¯¹é½çš„è¡Œ"""
    if not content_text or content_text == "N/A":
        return None
        
    # å¦‚æœæ˜¯æœ€åä¸€è¡Œï¼Œå»æ‰åº•éƒ¨è™šçº¿
    row_style = STYLE_ROW
    if is_last:
        row_style = row_style.replace("border-bottom: 1px dashed var(--nord04);", "")

    div = soup.new_tag('div', **{'style': row_style})
    
    # Label (å·¦ä¾§å›ºå®šå®½åº¦)
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ç”¨ class="chip" ç»§æ‰¿é¢œè‰²ï¼Œä½†ç”¨ style è¦†ç›–å¸ƒå±€å±æ€§
    label = soup.new_tag('span', **{'class': 'chip', 'style': 'width: 130px; text-align: center; flex-shrink: 0; margin-right: 15px; display: block; height: fit-content;'})
    label.string = label_text
    div.append(label)
    
    # Content (å³ä¾§è‡ªé€‚åº”)
    content = soup.new_tag('span', **{'style': STYLE_CONTENT})
    content.string = str(content_text)
    div.append(content)
    
    return div

# ----------------- æ„å»ºé¡µé¢ -----------------

if scored_papers:
    # é¡¶éƒ¨å®¹å™¨
    top_section = soup.new_tag('section', **{'class': 'day-container', 'style': 'margin-top: 20px; border: 2px solid var(--nord08); padding: 20px;'})
    
    # Header
    header_div = soup.new_tag('div', **{'class': 'date', 'style': 'padding-bottom: 15px; border-bottom: 2px solid var(--nord04); margin-bottom: 15px; font-size: 1.5em;'})
    header_div.string = f"ğŸ† Weekly Top Picks ({len(scored_papers)} Papers)"
    top_section.append(header_div)

    for paper in scored_papers:
        # å•ç¯‡è®ºæ–‡å¡ç‰‡ (å»æ‰å†…éƒ¨çš„ dashed borderï¼Œå› ä¸ºæˆ‘ä»¬ç§»åˆ°äº†æ¯ä¸€è¡Œé‡Œ)
        article = soup.new_tag('article', **{'style': 'margin-bottom: 30px; padding-bottom: 10px; border-bottom: 4px solid var(--nord04);'})
        details = soup.new_tag('details', **{'class': 'article-expander', 'open': 'true'})
        
        # === ç¬¬1éƒ¨åˆ†ï¼šæ ‡é¢˜åŒºåŸŸ (Score + Title + Pub) ===
        # ä½¿ç”¨ Flex å¸ƒå±€è®©åˆ†æ•°åœ¨å·¦ä¾§çªæ˜¾
        summary_tag = soup.new_tag('summary', **{'class': 'article-expander-title', 'style': 'display: flex; align-items: flex-start; padding-bottom: 10px; border-bottom: 1px solid var(--nord04); margin-bottom: 10px;'})
        
        # 1. Big Score (å·¦ä¾§å¤§æ•°å­—)
        # é¢œè‰²é€»è¾‘ï¼šåˆ†æ•°è¶Šé«˜è¶Šçº¢ï¼Œä½åˆ†åå†·è‰² (å¯é€‰)
        score_color = "var(--nord0B)" if paper['score'] >= 8 else "var(--nord0E)"
        score_div = soup.new_tag('div', **{'style': f'font-size: 2.2em; font-weight: 800; color: {score_color}; line-height: 1; margin-right: 20px; min-width: 40px; text-align: center;'})
        score_div.string = str(paper['score'])
        summary_tag.append(score_div)
        
        # å³ä¾§æ ‡é¢˜å®¹å™¨
        title_container = soup.new_tag('div', **{'style': 'flex-grow: 1;'})
        
        # 2. Title
        title_div = soup.new_tag('div', **{'style': 'font-size: 1.2em; font-weight: bold; line-height: 1.3; margin-bottom: 6px;'})
        title_div.string = paper['title']
        title_container.append(title_div)
        
        # 3. Publication Chip (å¦‚æœæœ‰)
        if paper.get('publication') and paper['publication'] != "N/A":
            pub_span = soup.new_tag('span', **{'class': 'chip', 'style': 'font-size: 0.8em;'})
            pub_span.string = paper['publication']
            title_container.append(pub_span)
        
        summary_tag.append(title_container)
        details.append(summary_tag)

        # === ç¬¬2éƒ¨åˆ†ï¼šä¿¡æ¯åˆ—è¡¨ (è§„æ•´çš„è¡Œ) ===
        
        # Container for rows
        rows_container = soup.new_tag('div', **{'style': 'padding-left: 10px;'})

        # --- Row: Links & Authors (ç‰¹æ®Šå¤„ç†ï¼Œä¸ç”¨ label) ---
        meta_row = soup.new_tag('div', **{'style': STYLE_ROW})
        
        # å·¦ä¾§å ä½ (ä¸ºäº†å¯¹é½) æˆ– ç›´æ¥æ”¾ Links
        # è¿™é‡Œæˆ‘ä»¬æŠŠ Links æ”¾åœ¨å·¦ä¾§ 130px åŒºåŸŸé‡Œï¼Œä½œè€…æ”¾åœ¨å³ä¾§
        links_div = soup.new_tag('div', **{'style': 'width: 130px; flex-shrink: 0; margin-right: 15px; display: flex; justify-content: center; gap: 10px;'})
        
        abs_link = paper['id']
        pdf_link = abs_link.replace('/abs/', '/pdf/').replace('v1', '').replace('v2', '').replace('v3', '') # ç®€å•ç²—æš´å»ç‰ˆæœ¬å·
        pdf_link = re.sub(r'v\d+$', '', pdf_link)

        link_a = soup.new_tag('a', href=abs_link, target="_blank", **{'style': 'text-decoration: none; color: var(--nord08); font-weight: bold;'})
        link_a.append(soup.new_tag('i', **{'class': 'ri-links-line', 'style': 'font-size: 1.2em;'}))
        links_div.append(link_a)
        
        pdf_a = soup.new_tag('a', href=pdf_link, target="_blank", **{'style': 'text-decoration: none; color: var(--nord0B); font-weight: bold;'})
        pdf_a.append(soup.new_tag('i', **{'class': 'ri-file-pdf-line', 'style': 'font-size: 1.2em;'}))
        links_div.append(pdf_a)
        
        meta_row.append(links_div)

        # Authors
        authors_text = soup.new_tag('span', **{'style': 'font-style: italic; color: var(--nord03); font-size: 0.95em; align-self: center;'})
        if isinstance(paper['authors'], list):
            authors_text.string = ", ".join(paper['authors'])
        else:
            authors_text.string = paper['authors']
        meta_row.append(authors_text)
        
        rows_container.append(meta_row)

        # --- Row: Title CN ---
        rows_container.append(create_styled_row(soup, "Title CN", paper.get('title_zh', '')))

        # --- Row: AI Keywords ---
        keywords = paper.get('keywords', [])
        if keywords:
            kw_str = " Â· ".join(keywords) if isinstance(keywords, list) else keywords
            rows_container.append(create_styled_row(soup, "AI Keywords", kw_str))

        # --- Row: AI Summary ---
        rows_container.append(create_styled_row(soup, "AI Summary", paper.get('summary', '')))

        # --- Row: AI Reason ---
        rows_container.append(create_styled_row(soup, "AI Reason", paper.get('reason', '')))

        # --- Row: Original Abstract ---
        rows_container.append(create_styled_row(soup, "Abstract", paper.get('abstract', '')))

        # --- Row: Comment ---
        rows_container.append(create_styled_row(soup, "Comment", paper.get('comment', '')))

        # --- Row: Categories (æœ€åä¸€è¡Œ) ---
        rows_container.append(create_styled_row(soup, "Categories", paper.get('category', ''), is_last=True))

        details.append(rows_container)
        article.append(details)
        top_section.append(article)

    # æ’å…¥åˆ° Header ä¹‹å
    header_container = soup.find('section', class_='header-container')
    if header_container:
        header_container.insert_after(top_section)
    else:
        soup.body.insert(0, top_section)

# å†™å›
with open("target/index.html", 'w') as f:
    f.write(str(soup.prettify()))

print("HTML injection complete. Visual upgrade applied.")
